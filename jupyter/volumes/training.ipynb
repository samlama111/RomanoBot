{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import ray.data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdfs import Config\n",
    "\n",
    "client = Config(path=\"./config/.hdfscli.cfg\").get_client(\n",
    "    \"dev\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert files, taken from populate_hdfs\n",
    "files_to_upload = [\"transfers.csv\",\"competitions.csv\", \"appearances.csv\", \"clubs.csv\", \"games.csv\", \"players.csv\"]\n",
    "\n",
    "remote_path = \"/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure remote path exists\n",
    "client.makedirs(remote_path)\n",
    "\n",
    "# Insert files, taken from populate_hdfs\n",
    "\n",
    "# Check if the file exists\n",
    "for file in files_to_upload:\n",
    "    local_path = f\"./data/{file}\"\n",
    "    print(f\"Checking if {file} exists in {remote_path}...\")\n",
    "    if client.status(remote_path + file, strict=False):\n",
    "        print(f\"{file} exists in {remote_path}!\")\n",
    "        continue\n",
    "\n",
    "    print(f\"{file} does not exist in {remote_path}!\")\n",
    "    print(f\"Uploading {file} to {remote_path}...\")\n",
    "    # Upload a file to tmp, to be processed further\n",
    "    client.upload(remote_path, local_path)\n",
    "\n",
    "print(f\"contents in {remote_path}: \", client.list(\"/data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize Ray\n",
    "ray.init(dashboard_host=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files\n",
    "\n",
    "from io import StringIO, BytesIO\n",
    "\n",
    "# Helper function to read CSV files from HDFS in chunks\n",
    "def read_csv_from_hdfs_in_chunks(client, file_path, chunksize=100000):\n",
    "    with client.read(file_path) as reader:\n",
    "        file_contents = reader.read()\n",
    "    \n",
    "    buffer = BytesIO(file_contents)\n",
    "    chunks = pd.read_csv(buffer, chunksize=chunksize)\n",
    "    return ray.data.from_pandas_refs([ray.put(chunk) for chunk in chunks])\n",
    "\n",
    "# Read CSV files\n",
    "transfers_ds = read_csv_from_hdfs_in_chunks(client, \"/data/transfers.csv\")\n",
    "clubs_ds = read_csv_from_hdfs_in_chunks(client, \"/data/clubs.csv\")\n",
    "competitions_ds = read_csv_from_hdfs_in_chunks(client, \"/data/competitions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "\n",
    "1. Remove entries where `transfer_fee == NaN`, since these entries are usually internal transfers (or from lower league youth teams).\n",
    "2. Filter entries where `market_value_in_eur == Nan`, since we assume it's hard to find any info about these players\n",
    "\n",
    "For now, we already execute/apply the filtering. But in the future, we will do all the processing first and then train our model on the batches, (hopefully) never applying `take_all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with null values in 'transfer_fee' and 'market_value_in_eur'\n",
    "def filter_transfers(batch):\n",
    "    return batch[\n",
    "        batch['transfer_fee'].notna() & \n",
    "        (~batch['transfer_fee'].isna()) & \n",
    "        batch['market_value_in_eur'].notna() & \n",
    "        (~batch['market_value_in_eur'].isna())\n",
    "    ]\n",
    "\n",
    "transfers_ds = transfers_ds.map_batches(filter_transfers, batch_format=\"pandas\")\n",
    "\n",
    "# Prepare clubs dataset\n",
    "clubs_df = clubs_ds.select_columns(['club_id', 'domestic_competition_id']).to_pandas()\n",
    "\n",
    "# Helper function for merging with clubs\n",
    "def merge_transfers_clubs(transfers_batch):\n",
    "    transfers_df = pd.DataFrame(transfers_batch)\n",
    "    \n",
    "    merged_from = transfers_df.merge(clubs_df, left_on='from_club_id', right_on='club_id', how='left', suffixes=('', '_from'))\n",
    "    merged_from = merged_from.rename(columns={'domestic_competition_id': 'from_competition_id'})\n",
    "    \n",
    "    merged_to = merged_from.merge(clubs_df, left_on='to_club_id', right_on='club_id', how='left', suffixes=('', '_to'))\n",
    "    merged_to = merged_to.rename(columns={'domestic_competition_id': 'to_competition_id'})\n",
    "    \n",
    "    return merged_to.drop(columns=['club_id', 'club_id_to', 'transfer_date'])\n",
    "\n",
    "# Merge transfers with clubs\n",
    "transfers_ds = transfers_ds.map_batches(merge_transfers_clubs, batch_format=\"pandas\")\n",
    "\n",
    "# Filter out null competition IDs\n",
    "transfers_ds = transfers_ds.filter(lambda row: row['from_competition_id'] is not None and row['to_competition_id'] is not None)\n",
    "\n",
    "# Prepare competitions dataset\n",
    "competitions_df = competitions_ds.select_columns(['competition_id', 'country_name', 'sub_type']).to_pandas()\n",
    "\n",
    "# Helper function for merging with competitions\n",
    "def merge_transfers_competitions(transfers_batch):\n",
    "    transfers_df = pd.DataFrame(transfers_batch)\n",
    "    \n",
    "    merged_from = transfers_df.merge(competitions_df, left_on='from_competition_id', right_on='competition_id', how='left', suffixes=('', '_from'))\n",
    "    merged_from = merged_from.rename(columns={'country_name': 'from_country_name', 'sub_type': 'from_sub_type'})\n",
    "    \n",
    "    merged_to = merged_from.merge(competitions_df, left_on='to_competition_id', right_on='competition_id', how='left', suffixes=('', '_to'))\n",
    "    merged_to = merged_to.rename(columns={'country_name': 'to_country_name', 'sub_type': 'to_sub_type'})\n",
    "    \n",
    "    return merged_to.drop(columns=['competition_id', 'competition_id_to'])\n",
    "\n",
    "# Merge transfers with competitions\n",
    "transfers_ds = transfers_ds.map_batches(merge_transfers_competitions, batch_format=\"pandas\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(transfers_ds.take(5))\n",
    "\n",
    "# If you need the final result as a Pandas DataFrame:\n",
    "# final_df = transfers_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "from io import StringIO\n",
    "\n",
    "with client.read(\"/data/transfers.csv\") as reader:\n",
    "    file_contents = reader.read().decode('utf-8')\n",
    "\n",
    "transfers_df = pd.read_csv(StringIO(file_contents))\n",
    "\n",
    "with client.read(\"/data/clubs.csv\") as reader:\n",
    "    file_contents = reader.read().decode('utf-8')\n",
    "\n",
    "clubs_df = pd.read_csv(StringIO(file_contents))\n",
    "\n",
    "with client.read(\"/data/competitions.csv\") as reader:\n",
    "    file_contents = reader.read().decode('utf-8')\n",
    "\n",
    "competitions_df = pd.read_csv(StringIO(file_contents))\n",
    "\n",
    "with client.read(\"/data/players.csv\") as reader:\n",
    "    file_contents = reader.read().decode('utf-8')\n",
    "\n",
    "players_df = pd.read_csv(StringIO(file_contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter transfers\n",
    "# 1. Remove entries where `transfer_fee == NaN`, since these entries are usually internal transfers (or from lower league youth teams).\n",
    "# 2. Filter entries where `market_value_in_eur == Nan`, since we assume it's hard to find any info about these players\n",
    "\n",
    "transfers_df = transfers_df[transfers_df['transfer_fee'].notna()]\n",
    "transfers_df = transfers_df[transfers_df['market_value_in_eur'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join tables\n",
    "transfers_df = transfers_df.merge(clubs_df[['club_id', 'domestic_competition_id']], left_on='from_club_id', right_on='club_id', how='left', validate='m:m')\n",
    "transfers_df = transfers_df.rename(columns={'domestic_competition_id': 'from_competition_id'})\n",
    "\n",
    "transfers_df = transfers_df.merge(clubs_df[['club_id', 'domestic_competition_id']], left_on='to_club_id', right_on='club_id', how='left', validate='m:m')\n",
    "transfers_df = transfers_df.rename(columns={'domestic_competition_id': 'to_competition_id'})\n",
    "\n",
    "transfers_df = transfers_df.drop(columns=['club_id_x', 'club_id_y', 'transfer_date'])\n",
    "transfers_df = transfers_df.dropna(subset=['from_competition_id', 'to_competition_id'])\n",
    "\n",
    "transfers_df = transfers_df.merge(competitions_df[['competition_id', 'country_name', 'sub_type']], left_on='from_competition_id', right_on='competition_id', how='left', validate='m:m')\n",
    "transfers_df = transfers_df.rename(columns={'country_name': 'from_country_name', 'sub_type': 'from_sub_type'})\n",
    "\n",
    "transfers_df = transfers_df.merge(competitions_df[['competition_id','country_name', 'sub_type']], left_on='to_competition_id', right_on='competition_id', how='left', validate='m:m')\n",
    "transfers_df = transfers_df.rename(columns={'country_name': 'to_country_name', 'sub_type': 'to_sub_type'})\n",
    "\n",
    "transfers_df = transfers_df.drop(columns=['competition_id_x', 'competition_id_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Potential additional steps)\n",
    "\n",
    "3. Remove retired players\n",
    "4. Drop `transfer_date` column, as we don't need it for anything (the `transfer_season` should be enough for everything time-related).\n",
    "5. Drop one of `from_club_name` or `from_club_id` (and the same for `to_club_...`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join players_df to transfers_df (columns last_season, country_of_birth, position, sub_position, contract_expiration_date, highest_market_value_in_eur)\n",
    "# using the player_id\n",
    "transfers_df = transfers_df.merge(players_df[['player_id', 'last_season', 'country_of_citizenship', 'position', 'sub_position', 'contract_expiration_date', 'highest_market_value_in_eur']], on='player_id', how='left', validate='m:m')\n",
    "\n",
    "# Filter 'retired' players \n",
    "transfers_df = transfers_df[transfers_df['last_season'] > 2023]\n",
    "\n",
    "transfers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other useful tables and their attributes\n",
    "\n",
    "# appearances.csv - minutes played, goals, assists\n",
    "# (Would be hard to map to individual players playing, e.g. how do we know who was on the pitch when a goal was scored or conceded?) \n",
    "# club_games.csv - own_position, opponent_goals, opponent_position\n",
    "# clubs.csv - domestic_competition_id, squad_size, average_age, foreigners_percentage, national_team_players, net_transfer_record, (maybe to filter outdated clubs) last_season\n",
    "# (IMO useless) competitions.csv\n",
    "# game_events.csv - player_id, type (goal, assist, card)\n",
    "# (To know no. of games started) game_lineups.csv - player_id, position, type (substitute, starter)\n",
    "# (IMO useless) games.csv\n",
    "# (Useful for training, to know the valuation at the time of transfer, maybe 1 year prior?) player_valuations.csv - date, market_value_in_eur, current_club_id, player_id\n",
    "# players.csv - last_season (filter retired players), country_of_birth, country_of_citizenship, position, sub_position, foot, height_in_cm, contract_expiration_date, agent_name, market_value_in_eur, highest_market_value_in_eur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables (This description is outdated)\n",
    "\n",
    "Independent - player information (from other tables), `market_value_in_eur`, `from_club_name`/`from_club_id`\n",
    "\n",
    "Dependant - `to_club_id`/`to_club_name`, `transfer_fee`\n",
    "\n",
    "Because we have multiple dependant variables, there would be two models - one regression one predicting the transfer fee and another one (classifier most likely) predicting the club ID/name.\n",
    "\n",
    "When using as a service, it'd be nice if `player_id` and `to_club_name` were only necessary inputs and the rest read from HDFS/other data storage.\n",
    "Let's presume that in these scenarios, the `transfer_season` would be the current one (24/25)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representing club names/ids the best way possible:\n",
    "- initially as IDs, but that could be interpreted as ordinality by the model\n",
    "- ideally as embeddings - either of the club name or combinations such as \"club country + league + club name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_transfers_df = transfers_df.copy()\n",
    "# Replace transfer_season with transfer_season_num\n",
    "prepared_transfers_df['transfer_season_end_year'] = prepared_transfers_df['transfer_season'].apply(lambda x: int(x.split('/')[0]) + 1)\n",
    "\n",
    "## Replace from_sub_type and to_sub_type columns from \"first_tier\", etc. with a number\n",
    "# All our transfers are first division for some reason\n",
    "prepared_transfers_df['from_sub_type_num'] = prepared_transfers_df['from_sub_type'].apply(lambda x: {'first_tier': 1, 'second_tier': 2, 'third_tier': 3, 'fourth_tier': 4}.get(x, 0))\n",
    "prepared_transfers_df['to_sub_type_num'] = prepared_transfers_df['to_sub_type'].apply(lambda x: {'first_tier': 1, 'second_tier': 2, 'third_tier': 3, 'fourth_tier': 4}.get(x, 0))\n",
    "\n",
    "# Replace countries with IDs for from_country_name, to_country_name, country_of_citizenship columns\n",
    "def get_country_id_mapping(df, columns):\n",
    "    all_countries = set()\n",
    "    for col in columns:\n",
    "        all_countries.update(df[col].unique())\n",
    "    return {country: idx for idx, country in enumerate(sorted(all_countries))}\n",
    "\n",
    "country_columns = ['from_country_name', 'to_country_name', 'country_of_citizenship']\n",
    "country_id_mapping = get_country_id_mapping(prepared_transfers_df, country_columns)\n",
    "\n",
    "for col in country_columns:\n",
    "    prepared_transfers_df[f'{col}_id'] = prepared_transfers_df[col].map(country_id_mapping)\n",
    "    prepared_transfers_df = prepared_transfers_df.drop(columns=[col])\n",
    "\n",
    "# Replace position and sub_position respectively using the same approach\n",
    "def get_position_id_mapping(df):\n",
    "    all_positions = df['position'].unique()\n",
    "    return {position: idx for idx, position in enumerate(sorted(all_positions))}\n",
    "\n",
    "position_mapping = get_position_id_mapping(prepared_transfers_df)\n",
    "\n",
    "prepared_transfers_df['position_id'] = prepared_transfers_df['position'].map(position_mapping)\n",
    "prepared_transfers_df = prepared_transfers_df.drop(columns=['position'])\n",
    "\n",
    "def get_sub_position_id_mapping(df):\n",
    "    all_sub_positions = df['sub_position'].unique()\n",
    "    return {sub_position: idx for idx, sub_position in enumerate(sorted(all_sub_positions))}\n",
    "\n",
    "sub_position_mapping = get_sub_position_id_mapping(prepared_transfers_df)\n",
    "\n",
    "prepared_transfers_df['sub_position_id'] = prepared_transfers_df['sub_position'].map(sub_position_mapping)\n",
    "prepared_transfers_df = prepared_transfers_df.drop(columns=['sub_position'])\n",
    "\n",
    "# Convert contract_expiration_date\n",
    "prepared_transfers_df['contract_expiration_date'] = pd.to_datetime(prepared_transfers_df['contract_expiration_date'])\n",
    "prepared_transfers_df['contract_expiration_date'] = prepared_transfers_df['contract_expiration_date'].dt.year\n",
    "\n",
    "train_features = ['player_id', 'from_club_id', 'market_value_in_eur', \n",
    "                  'transfer_season_end_year', 'from_sub_type_num', 'from_country_name_id', \n",
    "                  'country_of_citizenship_id', 'position_id', 'sub_position_id', \n",
    "                  'contract_expiration_date', 'highest_market_value_in_eur']\n",
    "\n",
    "X = prepared_transfers_df[train_features]\n",
    "y = prepared_transfers_df['to_club_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df = pd.DataFrame({'player_id': X_test['player_id'], 'predicted_club_id': y_pred})\n",
    "\n",
    "# Join y_pred_df with players_df on player_id\n",
    "y_pred_df = y_pred_df.merge(players_df[['player_id', 'name']], on='player_id', how='left')\n",
    "\n",
    "# Join y_pred_df with clubs_df on predicted_club_id\n",
    "y_pred_df = y_pred_df.merge(clubs_df[['club_id', 'name']], left_on='predicted_club_id', right_on='club_id', how='left')\n",
    "\n",
    "# Rename columns for clarity\n",
    "y_pred_df = y_pred_df.rename(columns={'name_x': 'player_name', 'name_y': 'predicted_club_name'})\n",
    "\n",
    "# Print y_pred_df\n",
    "print(y_pred_df[['player_id', 'player_name', 'predicted_club_id', 'predicted_club_name']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_transfer_probability(player_data, target_club_id):\n",
    "    # Ensure player_data has all necessary features\n",
    "    for feature in train_features:\n",
    "        if feature not in player_data:\n",
    "            raise ValueError(f\"Missing feature: {feature}\")\n",
    "    \n",
    "    # Create a 2D array with a single sample\n",
    "    input_data = np.array([player_data[feature] for feature in train_features]).reshape(1, -1)\n",
    "    \n",
    "    # Get probabilities for all classes\n",
    "    probabilities = clf.predict_proba(input_data)[0]\n",
    "    \n",
    "    # Find the index of the target club ID in the classes\n",
    "    target_index = np.where(clf.classes_ == target_club_id)[0]\n",
    "    \n",
    "    # Return the probability for the target club\n",
    "    if len(target_index) > 0:\n",
    "        return probabilities[target_index[0]]\n",
    "    else:\n",
    "        return 0.0  # Return 0 if the club ID is not in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Czech player\n",
    "example_player = X[X['player_id'] == 195778].loc[0]\n",
    "\n",
    "target_club_ids = [27, 31, 40, 984]  # Example club IDs\n",
    "\n",
    "for club_id in target_club_ids:\n",
    "    probability = predict_transfer_probability(example_player, club_id)\n",
    "    club_name = clubs_df[clubs_df['club_id'] == club_id]['name'].values[0]\n",
    "    print(f\"Probability of transfer to {club_name} (ID: {club_id}): {probability:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown Ray\n",
    "# ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
